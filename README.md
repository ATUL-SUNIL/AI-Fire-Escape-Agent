```markdown
# AI Fire Escape Agent ğŸƒğŸ”¥

A simulation project to evaluate the performance of intelligent agents navigating a building fire escape scenario under increasing environmental complexity.

By [Atul Sunil](https://github.com/ATUL-SUNIL)

---

## ğŸ“ Project Overview

This project explores the research question:

> **"How do different AI algorithms perform in fire escape scenarios with increasing complexity?"**

I designed an agent-based simulation where:
- Fire spreads dynamically across a grid-world
- An agent must reach an exit without being trapped by fire

---

## ğŸ’» Technologies Used

- Python 3.10+
- Numpy
- Matplotlib
- Plotly
- Custom grid environment + intelligent agents

---

## ğŸ§  Agents Implemented

| Agent Type | Description |
|------------|-------------|
| **Reactive Agent** | Rule-based agent with simple movement rules |
| **Search Agent** | A* search agent that computes shortest safe path |
| **Q-Learning Agent** | Reinforcement learning agent trained over multiple episodes |

Agents were tested on multiple:
- Grid sizes (`10x10`, `15x15`)
- Fire spread rates (`0.1`, `0.3`, `0.5`)

---

## ğŸ—ï¸ Project Structure

```

AI-Fire-Escape-Agent/
â”œâ”€â”€ agents/                  # Agent classes
â”œâ”€â”€ env/                     # Fire escape environment
â”œâ”€â”€ results/                 # Q-tables, outputs, animations
â”œâ”€â”€ train\_q\_agent.py         # Q-learning batch trainer
â”œâ”€â”€ run\_experiments.py       # Main evaluation experiments
â”œâ”€â”€ animate\_agent\_episode.py # Episode animation generator
â”œâ”€â”€ interactive\_agent\_comparison.py # Interactive results plot
â”œâ”€â”€ plot\_success\_curve.py    # (Optional) success rate visualisation
â”œâ”€â”€ README.md                # Project documentation

```

---

## ğŸš€ How to Run

1ï¸âƒ£ Clone the repository:
```

git clone [git@github.com](mailto:git@github.com)\:ATUL-SUNIL/AI-Fire-Escape-Agent.git
cd AI-Fire-Escape-Agent

```

2ï¸âƒ£ Install requirements:
```

pip install numpy matplotlib plotly

```

3ï¸âƒ£ Train Q-learning agents:
```

python train\_q\_agent.py

```

4ï¸âƒ£ Run evaluation experiments:
```

python run\_experiments.py

```

5ï¸âƒ£ Generate visualizations:
```

python animate\_agent\_episode.py
python interactive\_agent\_comparison.py

```

---

## ğŸ¥ Example Animation

<img src="results/agent_manual_colors_10x10_fs03.gif" width="500"/>

```

results/agent\_manual\_colors\_10x10\_fs03.gif

```

---

## ğŸ“Š Example Results Plot

Run:
```

python interactive\_agent\_comparison.py

```

Shows side-by-side success rates of all agents across grid sizes and fire spreads.

---

## ğŸ’¡ Key Findings

- **Search Agent (A\*)** consistently performed best in small grids by guaranteeing shortest paths
- **Q-Learning Agent** showed strong performance but suffered from incomplete exploration in limited training episodes
- **Reactive Agent** performed worst due to simplistic rule set

---

## ğŸ“ Coursework Reflection

This project demonstrates:
- Robust environment design
- Comparison of classical search, reinforcement learning, and reactive AI approaches
- Reproducibility and clear visual evaluation

Developed under COMP3004 / COMP4105 - Designing Intelligent Agents module at University of Nottingham.

---

## ğŸ“‹ Future Work

- Adding diagonal movement
- Multi-agent cooperative escape strategies
- Testing on larger dynamic grid environments

---

## ğŸ“œ License

This project was developed for educational and academic purposes only.
```

---
